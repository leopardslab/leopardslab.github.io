(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{Iynb:function(e){e.exports=JSON.parse('{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"8ebb4e09-e356-589f-b117-cd3bc009d2ba","frontmatter":{"title":"Clocal Azure","template":"project","description":"Clocal-azure provides an easy-to-use test/mocking framework for developing Cloud applications.","image":"/logos/projects/CloudAzure/cloud-azure.png","slug":"/projects/ClocalAzure"}}},{"node":{"id":"ee714369-9df9-531f-9007-347a0f423a98","frontmatter":{"title":"Dunner","template":"project","description":"Dunner is a task runner tool based on Docker, simple and flexible. You can define tasks and configure the environment in your .dunner.yaml file and then run as dunner do <taskname>.","image":"/logos/projects/Dunner/dunner.png","slug":"/projects/Dunner"}}},{"node":{"id":"ae81fe90-2d10-5565-a9d0-79b26388da55","frontmatter":{"title":"Gocloud","template":"project","description":"GoCloud is a golang library which hides the difference between different APIs provided by varied cloud providers (AWS, GCP, OpenStack etc.) and allows you to manage different cloud resources through a unified and easy to use API.","image":"/logos/projects/GoCloud/go-cloud.png","slug":"/projects/Gocloud"}}},{"node":{"id":"c948651a-51c1-5952-8c83-7a5bf7c1a81e","frontmatter":{"title":"Installer.to","template":"project","description":"We are a community managed list of installer scripts for popular tools for Linux based OS.","image":"/logos/projects/InstallerTo/installer-to.png","slug":"/projects/Installer"}}},{"node":{"id":"f416f8a9-2a90-54bf-9177-3b47433341fc","frontmatter":{"title":"Raven","template":"project","description":"Raven is a cloud-native API monitoring tool to monitor the health of 3rd party APIs","image":"/images/placeholder.png","slug":"/projects/Raven"}}},{"node":{"id":"46f38887-e53f-5d5e-9eb2-8908ee5d0253","frontmatter":{"title":"Nodecloud CLI","template":"project","description":"Nodecloud-cli is an unified command line interface for open cloud based on nodecloud. nodecloud-cli supports cloud providers like AWS, Azure, GCP and many more.","image":"/logos/projects/NodeCloudCli/node-cloud-cli.png","slug":"/projects/NodecloudCli"}}},{"node":{"id":"c1c53fd0-2227-5451-bb9f-713e986e4a26","frontmatter":{"title":"Ukiyo","template":"project","description":"Ukiyo will act as a watcher for docker containers. It will run alongside with the other running containers and will be responsible for automatic updates. Updates will be based on push based model compared to existing solutions such as watchtower and ouroboros. Push events will be recived from ukiyo via webhooks. Docker registries provide webhooks to subscribe and listen to image changes. Locally running images will change only after such an event is received by ukiyo. Pull based model can be implemented as an optional way of updating the running containers.","image":"/images/placeholder.png","slug":"/projects/Ukiyo"}}},{"node":{"id":"971b8c44-1d1d-50fc-a479-62a40b46a73b","frontmatter":{"title":"CrawlerX","template":"project","description":"The CrawlerX is a platform which we can use for crawl web URLs in different kind of protocols in a distributed way. Web crawling often called web scraping is a method of programmatically going over a collection of web pages and extracting data which useful for data analysis with web-based data. With a web scraper, you can mine data about a set of products, get a large corpus of text or quantitative data to play around with, get data from a site without an official API, or just satisfy your own personal curiosity.","image":"/logos/projects/CrawlerX/crawler-x.png","slug":"/projects/CrawlerX"}}},{"node":{"id":"8ad8bf9b-dd75-51dc-9a4b-51279dd489c5","frontmatter":{"title":"Node Cloud","template":"project","description":"Node Cloud is a standard library to get a single API on the open cloud with multiple providers. It is a NodeJs library which comes with plugins for each cloud provider. NodeCloud\'s aim is to abstract away the differences between different cloud providers. It provides an easy to use API for developers in order to interact with different cloud providers.","image":"/logos/projects/NodeCloud/node-cloud.png","slug":"/projects/NodeCloud"}}}]}}}')},RXBc:function(e,t,o){"use strict";o.r(t);o("91GP");var a=o("q1tI"),n=o.n(a),i=o("pc/7"),r=o("muT7"),s=o("SQ6y"),l=o("jfxn"),d=o("wtQ5"),c=o("8bOL");t.default=function(){var e,t=(e=i.data.allMarkdownRemark).edges.length>0?e.edges[0].node.frontmatter:null,o=Object(r.a)(),a=Object(s.a)(),u=t.headerSecton,p=t.aboutSection,m=t.projectsSection,g=o.map((function(e){return Object.assign({id:e.node.id},e.node.frontmatter)}));return n.a.createElement(l.a,null,n.a.createElement(d.a,{title:"Leopards Labs Home Page"}),n.a.createElement(c.g,{mainText:u.mainText,subText:u.subText,buttonText:u.buttonText,buttonLink:u.buttonLink,image:u.image}),n.a.createElement(c.b,{title:p.title,mainText:p.mainText,sideComponent:n.a.createElement(c.l,{title:"Recent Articles",mediumUrl:p.mediumUrl,small:!0,limit:3})}),n.a.createElement(c.p,{title:m.title,items:g,limit:6,suffle:!0}),n.a.createElement("br",null),n.a.createElement(c.d,{title:a.gitterRoomsListHeading,gitterOrganizationName:a.gitterOrganizationName,gitterToken:a.gitterToken}),n.a.createElement(c.k,{title:a.mailingListHeading,feedUrl:a.mailingListFeedUrl}),n.a.createElement("br",null),n.a.createElement("br",null),n.a.createElement("br",null))}},muT7:function(e,t,o){"use strict";o.d(t,"a",(function(){return n}));var a=o("Iynb"),n=function(){return a.data.allMarkdownRemark.edges}},"pc/7":function(e){e.exports=JSON.parse('{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"f7b3429a-263d-59e9-a097-d96ec5f5a084","frontmatter":{"headerSecton":{"mainText":"WELCOME To Leopards Lab","subText":"The Leopards Lab has conducted research covering various aspects of sensor networks, embeded systems, digital forensic, information security, mobile applications, cloud, blockchain and software tools.","buttonText":"EXPLORE","buttonLink":"/projects","image":"/logos/logo-secondary.png"},"aboutSection":{"title":"About Us","mainText":"The Leopards Lab has conducted research covering various aspects of sensor networks, embeded systems, digital forensic, information security, mobile applications, cloud, blockchain and software tools. The goal of our research is to generate computing solutions through identifying low cost methodologies and strategies that lead to sustainability.At present, the Leopards Lab group is at a stage of its evolution in which it has been able to secure high donor confidence as evidenced by simultaneous foreign funded projects. Leopards Lab group studies and produces sustainable computing solutions with respect to low cost computing and communication foundations in the developing and emerging regions in the world. We have developed several affordable and sustainable ICT solutions specially focusing the requirements in the developing region. These solutions are briefly described in the projects section.","mediumUrl":"https://medium.com/feed/leopards-lab"},"projectsSection":{"title":"Projects"},"contactSection":{"contactMessage":"Let us know if you have any queries regarding the organization","subscribeMessage":"Subscribe to our mailing list to stay in touch"}}}}]}}}')}}]);
//# sourceMappingURL=component---src-pages-index-js-fe67d9e00b0e77a9a0ba.js.map